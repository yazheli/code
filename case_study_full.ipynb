{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sr157Vcy_ksw"
      },
      "source": [
        "# Import packages needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tkYXmTaj_ksx"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import shap\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rds2J98W_ksz"
      },
      "source": [
        "# Utility functions\n",
        "## Below are a few utility functions that can help generate additional features and enrich dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RlqUurun_ksz"
      },
      "outputs": [],
      "source": [
        "def add_multiple_rolling_means(df, column, windows):\n",
        "    \"\"\"\n",
        "    Given a DataFrame, a column name, and a list of window sizes, this function:\n",
        "    1. Computes the rolling mean for each window size and adds new columns to the DataFrame.\n",
        "    2. Plots the original column and the newly created rolling mean columns on the same figure.\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    # Compute rolling means and create new columns\n",
        "    rolling_cols = []\n",
        "    for w in windows:\n",
        "        new_col_name = f'{column} {w}D Mean'\n",
        "        df[new_col_name] = df[column].rolling(window=w).mean()\n",
        "        rolling_cols.append(new_col_name)\n",
        "\n",
        "    # Plot the original column and the rolling mean columns\n",
        "    plot_cols = [column] + rolling_cols\n",
        "    df[plot_cols].plot(figsize=(10, 6))\n",
        "    plt.title(f\"{column} with Rolling Means\")\n",
        "    plt.xlabel(\"Date\")\n",
        "    plt.ylabel(column)\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "    return df\n",
        "\n",
        "def add_column_differences(df, target_col, cols):\n",
        "    \"\"\"\n",
        "    Given a DataFrame, a target column, and a list of other column names, calculates the difference between the target column and each of the listed columns, and creates new columns with the results.\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "    for c in cols:\n",
        "        df[f'{c} - {target_col}'] = df[c] - df[target_col]\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2v0O-DJA_ksz"
      },
      "source": [
        "# Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "p17lJ-qo_ksz",
        "outputId": "9dead005-a465-4a58-9c5e-945391e35dfe"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'Data Intel Project - Data Only.xlsx'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-9cbd3a9b751d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Data Intel Project - Data Only.xlsx'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msheet_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Returns Static'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'openpyxl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Returns Static'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Unnamed: 2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[1;32m    493\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m         io = ExcelFile(\n\u001b[0m\u001b[1;32m    496\u001b[0m             \u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[1;32m   1565\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage_options\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1567\u001b[0;31m         self._reader = self._engines[engine](\n\u001b[0m\u001b[1;32m   1568\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1569\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/excel/_openpyxl.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath_or_buffer, storage_options, engine_kwargs)\u001b[0m\n\u001b[1;32m    551\u001b[0m         \"\"\"\n\u001b[1;32m    552\u001b[0m         \u001b[0mimport_optional_dependency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"openpyxl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m    554\u001b[0m             \u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath_or_buffer, storage_options, engine_kwargs)\u001b[0m\n\u001b[1;32m    561\u001b[0m         )\n\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mExcelFile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workbook_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m    564\u001b[0m                 \u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Data Intel Project - Data Only.xlsx'"
          ]
        }
      ],
      "source": [
        "data = pd.read_excel('Data Intel Project - Data Only.xlsx', sheet_name=['Returns Static'], engine='openpyxl')['Returns Static'].drop(columns = 'Unnamed: 2').set_index('Date')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ev_xfykH_ks0"
      },
      "source": [
        "# Handle outlier in Economic Index column"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJxzNbYQ_ks0"
      },
      "source": [
        "In the Economic Index column, we have some entries recorded as 200, and others with extremely large values. Based on prior knowledge, it appears that these large values are due to a missing decimal separator. To correct them, we can divide these extreme values by 1000 to restore them to their intended scale. For entries that are exactly 200, we will apply a linear interpolation at a later stage to replace them with more realistic values consistent with the rest of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0m02MX9e_ks0"
      },
      "outputs": [],
      "source": [
        "data.loc[data['Economic Index']>200, 'Economic Index'] = data.loc[data['Economic Index']>200, 'Economic Index'] / 1000\n",
        "data.loc[data['Economic Index']>=200, 'Economic Index'] = np.nan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYrmYZcd_ks1"
      },
      "source": [
        "# Feature energing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZPlonzt_ks1"
      },
      "source": [
        "## We made a log transfrom to the \"Stock Market\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bLrc-cfl_ks1"
      },
      "outputs": [],
      "source": [
        "data['Stock Market Log Scale'] = np.log(data['Stock Market'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pio9gpHN_ks2"
      },
      "source": [
        "## Transform RSI into Binary Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0w-lr1Xw_ks2"
      },
      "outputs": [],
      "source": [
        "data['RSI Oversold'] = data['RSI'] < 30\n",
        "data['RSI Neutral'] = data['RSI'].between(30, 70, inclusive='both')\n",
        "data['RSI Overbought'] = data['RSI'] > 70"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cu9I8WMx_ks2"
      },
      "source": [
        "## Smoothing\n",
        "Cloumn \"New Sentiment\" , \"Economic Index\" “Commodities Price Index”，are volatie on a day by day basis, here we use N day moving average to smoothe them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1T2Lnc0d_ks2"
      },
      "outputs": [],
      "source": [
        "data = add_multiple_rolling_means(data, 'News Sentiment', [10, 30, 90])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gsfsrTQs_ks2"
      },
      "outputs": [],
      "source": [
        "plot_cols =  ['News Sentiment 10D Mean', 'News Sentiment 30D Mean', 'News Sentiment 90D Mean']\n",
        "\n",
        "data[plot_cols].plot(figsize=(10, 6), ax = plt.gca())\n",
        "\n",
        "plt.title(\"News Sentiment with Rolling Means\")\n",
        "plt.xlabel(\"Date\")\n",
        "plt.ylabel(\"News Sentiment\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1u3fRYib_ks3"
      },
      "outputs": [],
      "source": [
        "data.dropna(subset=['Stock Market'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MQN3Blcr_ks3"
      },
      "outputs": [],
      "source": [
        "data['Economic Index'] = data['Economic Index'].interpolate(method='linear', axis=0).ffill()\n",
        "data = add_multiple_rolling_means(data, 'Economic Index', [5, 10, 30])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8caNYrG2_ks3"
      },
      "outputs": [],
      "source": [
        "data = add_multiple_rolling_means(data, 'Commodities Price Index', [5, 10, 30])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jY052FFu_ks3"
      },
      "source": [
        "we also smootth out lag scaled price, this will be used to indicate the trend between different terms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QAM8vY6N_ks3"
      },
      "outputs": [],
      "source": [
        "data = add_multiple_rolling_means(data, 'Stock Market Log Scale', [5, 10, 20])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E0mufbhM_ks3"
      },
      "outputs": [],
      "source": [
        "data = add_multiple_rolling_means(data, 'Stock Market', [5, 10, 20])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpwLOzxw_ks7"
      },
      "outputs": [],
      "source": [
        "corr_matrix = data[['Stock Market', 'RSI', 'News Sentiment', 'Forward EPS Estimate', 'Economic Index', 'Commodities Price Index']].corr()\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(\n",
        "    corr_matrix,\n",
        "    annot=False,\n",
        "    fmt=\".2f\",\n",
        "    cmap='coolwarm',\n",
        "    square=True,\n",
        "    linewidths=.5\n",
        ")\n",
        "plt.title('Correlation Heatmap')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QKSkqrW_ks7"
      },
      "source": [
        "## Differicing\n",
        "We will further enhance our feature set by calculating differences between various N-day moving averages. The rationale behind this is that these differences can highlight the relative strength of the underlying trend."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zhTJzJwA_ks7"
      },
      "outputs": [],
      "source": [
        "data = add_column_differences(data, 'Stock Market Log Scale 20D Mean', ['Stock Market Log Scale 5D Mean', 'Stock Market Log Scale 10D Mean'])\n",
        "data = add_column_differences(data, 'News Sentiment 90D Mean', ['News Sentiment 10D Mean', 'News Sentiment 30D Mean'])\n",
        "data = add_column_differences(data, 'Commodities Price Index 30D Mean', ['Commodities Price Index 5D Mean', 'Commodities Price Index 10D Mean'])\n",
        "data = add_column_differences(data, 'Economic Index 30D Mean', ['Economic Index 5D Mean', 'Economic Index 10D Mean'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnMITpEM_ks7"
      },
      "source": [
        "# Modeling\n",
        "All the features we’ve created are based on historical data, which prevents any risk of data leakage. We will use a selection of these features—under the assumption of a 10-day holding period—to predict the probability that the price will rise or fall over the following 10 days."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "st70ocWI_ks7"
      },
      "outputs": [],
      "source": [
        "features = ['RSI Oversold',\n",
        "            'RSI Neutral',\n",
        "            'RSI Overbought',\n",
        "            'Stock Market Log Scale 5D Mean - Stock Market Log Scale 20D Mean',\n",
        "            'Stock Market Log Scale 10D Mean - Stock Market Log Scale 20D Mean',\n",
        "            'Economic Index 5D Mean - Economic Index 30D Mean',\n",
        "            'Economic Index 10D Mean - Economic Index 30D Mean',\n",
        "            'News Sentiment 10D Mean - News Sentiment 90D Mean',\n",
        "            'News Sentiment 30D Mean - News Sentiment 90D Mean',\n",
        "            'Commodities Price Index 5D Mean - Commodities Price Index 30D Mean',\n",
        "            'Commodities Price Index 10D Mean - Commodities Price Index 30D Mean']\n",
        "data['Stock Market Log Scale 10D Move'] = data['Stock Market Log Scale'].shift(-10) - data['Stock Market Log Scale']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rh_9L544_ks7"
      },
      "outputs": [],
      "source": [
        "corr_matrix = data[features+['Stock Market Log Scale 10D Move']].corr()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZP5sTkzO_ks8"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(\n",
        "    corr_matrix,\n",
        "    annot=True,\n",
        "    fmt=\".2f\",\n",
        "    cmap='coolwarm',\n",
        "    square=True,\n",
        "    linewidths=.5\n",
        ")\n",
        "plt.title('Correlation Heatmap')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CGMwpjVX_ks8"
      },
      "outputs": [],
      "source": [
        "x_col = 'News Sentiment 30D Mean - News Sentiment 90D Mean'\n",
        "y_col = 'Stock Market Log Scale 10D Move'\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "sns.regplot(\n",
        "    x=x_col,\n",
        "    y=y_col,\n",
        "    data=data,\n",
        "    ci=95,\n",
        "    scatter_kws={'alpha': 0.6}\n",
        ")\n",
        "\n",
        "plt.title('Regression of Stock Market Move vs. News Sentiment (30D - 90D) Difference')\n",
        "plt.xlabel('News Sentiment (30D Mean - 90D Mean)')\n",
        "plt.ylabel('Stock Market Log Scale 10D Move')\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BG_7rjyK_ks8"
      },
      "outputs": [],
      "source": [
        "x_col = 'News Sentiment 10D Mean - News Sentiment 90D Mean'\n",
        "y_col = 'Stock Market Log Scale 10D Move'\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "sns.regplot(\n",
        "    x=x_col,\n",
        "    y=y_col,\n",
        "    data=data,\n",
        "    ci=95,\n",
        "    scatter_kws={'alpha': 0.6}\n",
        ")\n",
        "\n",
        "plt.title('Regression of Stock Market Move vs. News Sentiment (10D - 90D) Difference')\n",
        "plt.xlabel('News Sentiment (10D Mean - 90D Mean)')\n",
        "plt.ylabel('Stock Market Log Scale 10D Move')\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CNmPEFXU_ks8"
      },
      "outputs": [],
      "source": [
        "x_col = 'RSI'\n",
        "y_col = 'Stock Market Log Scale 10D Move'\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "sns.regplot(\n",
        "    x=x_col,\n",
        "    y=y_col,\n",
        "    data=data,\n",
        "    ci=95,\n",
        "    scatter_kws={'alpha': 0.6}\n",
        ")\n",
        "\n",
        "plt.title('Regression of Stock Market Move vs. News Sentiment Difference')\n",
        "plt.xlabel('News Sentiment (30D Mean - 90D Mean)')\n",
        "plt.ylabel('Stock Market Log Scale 10D Move')\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NFiYb2HN_ks8"
      },
      "outputs": [],
      "source": [
        "data['RSI Category'] = pd.cut(\n",
        "    data['RSI'],\n",
        "    bins=[0, 30, 70, 100],\n",
        "    labels=['Oversold', 'Neutral', 'Overbought']\n",
        ")\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "sns.violinplot(\n",
        "    x='RSI Category',\n",
        "    y='Stock Market Log Scale 10D Move',\n",
        "    data=data\n",
        ")\n",
        "\n",
        "plt.title('Stock Market Log Scale 10D Move by RSI Category')\n",
        "plt.xlabel('RSI Category')\n",
        "plt.ylabel('Stock Market Log Scale 10D Move')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UCX354hF_ks9"
      },
      "outputs": [],
      "source": [
        "x_col = 'Stock Market Log Scale 10D Mean - Stock Market Log Scale 20D Mean'\n",
        "y_col = 'Stock Market Log Scale 10D Move'\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "sns.regplot(\n",
        "    x=x_col,\n",
        "    y=y_col,\n",
        "    data=data,\n",
        "    ci=95,\n",
        "    scatter_kws={'alpha': 0.6}\n",
        ")\n",
        "\n",
        "plt.title('Regression: Stock Market Log Scale 10D Move vs. (10D - 20D) Difference')\n",
        "plt.xlabel('Stock Market Log Scale (10D Mean - 20D Mean)')\n",
        "plt.ylabel('Stock Market Log Scale 10D Move')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_qWYXlyn_ks9"
      },
      "outputs": [],
      "source": [
        "x_col = 'Commodities Price Index 5D Mean - Commodities Price Index 30D Mean'\n",
        "y_col = 'Stock Market Log Scale 10D Move'\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "sns.regplot(\n",
        "    x=x_col,\n",
        "    y=y_col,\n",
        "    data=data,\n",
        "    ci=95,\n",
        "    scatter_kws={'alpha': 0.6}\n",
        ")\n",
        "\n",
        "plt.title('Regression of Stock Market Move vs. Commodities Price Index (5D - 30D) Difference')\n",
        "plt.xlabel('Commodities Price Index (5D Mean - 30D Mean)')\n",
        "plt.ylabel('Stock Market Log Scale 10D Move')\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IitHJlSy_ks9"
      },
      "outputs": [],
      "source": [
        "x_col = 'Commodities Price Index 10D Mean - Commodities Price Index 30D Mean'\n",
        "y_col = 'Stock Market Log Scale 10D Move'\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "sns.regplot(\n",
        "    x=x_col,\n",
        "    y=y_col,\n",
        "    data=data,\n",
        "    ci=95,\n",
        "    scatter_kws={'alpha': 0.6}\n",
        ")\n",
        "\n",
        "plt.title('Regression of Stock Market Move vs. Commodities Price Index (10D - 30D) Difference')\n",
        "plt.xlabel('News Sentiment (10D Mean - 30D Mean)')\n",
        "plt.ylabel('Stock Market Log Scale 10D Move')\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_col = 'Economic Index 5D Mean - Economic Index 30D Mean'\n",
        "y_col = 'Stock Market Log Scale 10D Move'\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "sns.regplot(\n",
        "    x=x_col,\n",
        "    y=y_col,\n",
        "    data=data,\n",
        "    ci=95,\n",
        "    scatter_kws={'alpha': 0.6}\n",
        ")\n",
        "\n",
        "plt.title('Regression of Stock Market Move vs. Economic Index (5D - 30D) Difference')\n",
        "plt.xlabel('Economic Index (5D Mean - 30D Mean)')\n",
        "plt.ylabel('Stock Market Log Scale 10D Move')\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "U-bonYZrg2KI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_col = 'Economic Index 10D Mean - Economic Index 30D Mean'\n",
        "y_col = 'Stock Market Log Scale 10D Move'\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "sns.regplot(\n",
        "    x=x_col,\n",
        "    y=y_col,\n",
        "    data=data,\n",
        "    ci=95,\n",
        "    scatter_kws={'alpha': 0.6}\n",
        ")\n",
        "\n",
        "plt.title('Regression of Stock Market Move vs. Economic Index (10D - 30D) Difference')\n",
        "plt.xlabel('Economic Index (10D Mean - 30D Mean)')\n",
        "plt.ylabel('Stock Market Log Scale 10D Move')\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rtGDZknEg2S_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kcnWfRa8_ks9"
      },
      "outputs": [],
      "source": [
        "data = data.drop(columns = 'Average Precipitation over last month').dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ct7lLoBl_ks9"
      },
      "outputs": [],
      "source": [
        "features = ['Stock Market Log Scale 5D Mean - Stock Market Log Scale 20D Mean',\n",
        "            'Commodities Price Index 5D Mean - Commodities Price Index 30D Mean',\n",
        "            'News Sentiment 10D Mean - News Sentiment 90D Mean',\n",
        "            'Economic Index 5D Mean - Economic Index 30D Mean'\n",
        "            ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtAXQ-PR_ks9"
      },
      "source": [
        "Using a binary definition for y can oversimplify the target variable by ignoring its scale. However, for simplicity, we define y as whether the stock price will be higher in 10 days."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ErlMy28e_ks9"
      },
      "outputs": [],
      "source": [
        "X = data[features].values\n",
        "y = data['Stock Market Log Scale 10D Move'] > 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dIzomQIH_ks-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TKiYw4FG_ks-"
      },
      "outputs": [],
      "source": [
        "tscv = TimeSeriesSplit(n_splits=5)\n",
        "param_grid = {\n",
        "    'n_estimators': [10, 30, 60, 90],\n",
        "    'max_depth': [5, 10, 15]\n",
        "}\n",
        "\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Using 'roc_auc' scoring to measure how well the model distinguishes upward moves\n",
        "grid = GridSearchCV(rf, param_grid, cv=tscv, scoring='roc_auc', n_jobs=-1)\n",
        "grid.fit(X, y)\n",
        "best_model = grid.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oBkDWxSM_ks-"
      },
      "outputs": [],
      "source": [
        "best_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HONolSuL_ks-"
      },
      "outputs": [],
      "source": [
        "plt.plot(best_model.predict_proba(X)[:,1])\n",
        "plt.axhline(y=0.5, color='red', linestyle='--')\n",
        "plt.plot(y.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OFkEMWja_ks-"
      },
      "outputs": [],
      "source": [
        "importances = best_model.feature_importances_\n",
        "indices = np.argsort(importances)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.barh(range(len(indices)), importances[indices], align='center')\n",
        "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
        "plt.xlabel('Relative Importance')\n",
        "plt.title('Random Forest Feature Importances')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = X.astype(np.float64)"
      ],
      "metadata": {
        "id": "i1fwsFraAepO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-p0Oy6GG_ks-"
      },
      "outputs": [],
      "source": [
        "explainer = shap.Explainer(best_model, X)\n",
        "shap_values = explainer(X)\n",
        "shap_values_class1 = shap_values[:, :, 1]\n",
        "shap.summary_plot(shap_values_class1, X)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dict(zip(range(len(features)),features))"
      ],
      "metadata": {
        "id": "uFoVJdLpBBwm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Fo9zDb1_ks-"
      },
      "source": [
        "# Backtest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x_xyOJ4d_ktA"
      },
      "outputs": [],
      "source": [
        "def sharpe_ratio(returns, risk_free_rate=0.0, periods_per_year=252):\n",
        "    \"\"\"\n",
        "    Calculate the annualized Sharpe Ratio.\n",
        "    \"\"\"\n",
        "    returns = pd.Series(returns)\n",
        "    avg_return_periodic = returns.mean()\n",
        "    avg_return_annualized = avg_return_periodic * periods_per_year\n",
        "    std_return_periodic = returns.std()\n",
        "    std_return_annualized = std_return_periodic * np.sqrt(periods_per_year)\n",
        "    sharpe = (avg_return_annualized - risk_free_rate) / std_return_annualized\n",
        "    return sharpe\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YMFfcwmv_ktA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "li9Q_Qfw_ktA"
      },
      "outputs": [],
      "source": [
        "def train_and_predict(X, y, train_indices, test_indices, model):\n",
        "    X_train, X_test = X[train_indices, :], X[test_indices, :]\n",
        "    y_train, y_test = y.iloc[train_indices], y.iloc[test_indices]\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict_proba(X_test)\n",
        "    priority_prob = (y_train.sum()/len(y_train))\n",
        "\n",
        "    return y_test, y_pred, priority_prob\n",
        "\n",
        "def initialize_price_history(data, y_test, y_pred):\n",
        "    price_history = data.loc[y_test.index, :].copy().reset_index()\n",
        "    price_history['rise_probability'] = y_pred[:, 1]\n",
        "    price_history['y_test'] = y_test.astype(int)\n",
        "    return price_history\n",
        "\n",
        "def execute_trading_strategy(price_history, initial_fund=10000, threshold=0.5):\n",
        "    fund = initial_fund\n",
        "    portfolio = {}\n",
        "    i = 0\n",
        "\n",
        "    while i < price_history.shape[0]:\n",
        "        if (price_history.iloc[i]['rise_probability'] > threshold) and (i + 10 < price_history.shape[0]):\n",
        "            #print(f\"buy at {price_history.iloc[i]['Date']}\")\n",
        "            share_hold = fund / price_history.iloc[i]['Stock Market']\n",
        "            i += 10\n",
        "            fund = share_hold * price_history.iloc[i]['Stock Market']\n",
        "            #print(f\"exit with {int(fund)}\")\n",
        "        else:\n",
        "            i += 1\n",
        "\n",
        "        portfolio[i] = fund\n",
        "\n",
        "    return portfolio\n",
        "\n",
        "def calculate_buy_and_hold(price_history, initial_fund=10000):\n",
        "    first_price = price_history['Stock Market'].iloc[0]\n",
        "    shares_bh = initial_fund / first_price\n",
        "    price_history['buy&hold'] = shares_bh * price_history['Stock Market']\n",
        "    return price_history\n",
        "\n",
        "def finalize_portfolio(price_history, portfolio):\n",
        "    portfolio_series = pd.Series(portfolio)\n",
        "    full_range = range(0, portfolio_series.index.max() + 1)\n",
        "    portfolio_series = portfolio_series.reindex(full_range)\n",
        "\n",
        "    price_history['portfolio'] = (\n",
        "        (portfolio_series / price_history['Stock Market'])\n",
        "        .ffill() * price_history['Stock Market']\n",
        "    ).fillna(price_history['buy&hold'])\n",
        "\n",
        "    price_history['strategy'] = price_history['portfolio']\n",
        "    return price_history\n",
        "\n",
        "def calculate_sharpe_ratios(price_history, sharpe_ratio_func):\n",
        "    strategy_returns = price_history['strategy'].pct_change()\n",
        "    bh_returns = price_history['buy&hold'].pct_change()\n",
        "\n",
        "    sr_strategy = sharpe_ratio_func(strategy_returns)\n",
        "    sr_buy_hold = sharpe_ratio_func(bh_returns)\n",
        "\n",
        "    return sr_strategy, sr_buy_hold\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_backtest(X, y, tscv, best_model, data, sharpe_ratio_func):\n",
        "    results = []\n",
        "\n",
        "    for j, (train_indices, test_indices) in enumerate(tscv.split(X)):\n",
        "        y_test, y_pred, priority_prob = train_and_predict(X, y, train_indices, test_indices, best_model)\n",
        "        price_history = initialize_price_history(data, y_test, y_pred)\n",
        "\n",
        "        portfolio = execute_trading_strategy(price_history, threshold=priority_prob)\n",
        "        price_history = calculate_buy_and_hold(price_history)\n",
        "        price_history = finalize_portfolio(price_history, portfolio)\n",
        "\n",
        "        sr_strategy, sr_buy_hold = calculate_sharpe_ratios(price_history, sharpe_ratio_func)\n",
        "\n",
        "        #print(f\"Fold {j} - Sharpe(Strategy): {sr_strategy:.3f} | Sharpe(Buy&Hold): {sr_buy_hold:.3f}\")\n",
        "\n",
        "        results.append({\n",
        "            'fold': j,\n",
        "            'sharpe_strategy': sr_strategy,\n",
        "            'sharpe_buy_and_hold': sr_buy_hold,\n",
        "            'price_history': price_history.copy()\n",
        "        })\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "0K2DMPRn4Bc-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "0oXDryi8_ktA"
      },
      "outputs": [],
      "source": [
        "results = run_backtest(X, y, tscv, best_model, data, sharpe_ratio)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rCKbrgnM_ktB"
      },
      "outputs": [],
      "source": [
        "strategy_sharpes = [results[i]['sharpe_strategy'] for i in range(5)]\n",
        "buyhold_sharpes = [results[i]['sharpe_buy_and_hold'] for i in range(5)]\n",
        "time_range = [results[i]['price_history']['Date'].min().strftime('%Y-%m-%d') + ' to ' + results[i]['price_history']['Date'].max().strftime('%Y-%m-%d') for i in range(5)]\n",
        "\n",
        "sharpes = pd.DataFrame({\n",
        "    'Testing Window': time_range,\n",
        "    'Sharpe (Strategy)': strategy_sharpes,\n",
        "    'Sharpe (Buy & Hold)': buyhold_sharpes\n",
        "\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mD19OVse_ktB"
      },
      "outputs": [],
      "source": [
        "sharpes"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "returns = []\n",
        "for i in range(5):\n",
        "    final_values = results[i]['price_history'][['strategy', 'buy&hold']].iloc[-1] / 100 - 100\n",
        "    returns.append(final_values)\n",
        "\n",
        "# Create a DataFrame from the results\n",
        "returns_df = pd.DataFrame(returns, columns=['strategy', 'buy&hold'])\n",
        "returns_df.reset_index(drop=True, inplace=True)\n",
        "returns_df.columns = ['Strategy Return (%)', 'Buy & Hold Return (%)']\n",
        "\n",
        "returns_df"
      ],
      "metadata": {
        "id": "_0RDS3qUsh4W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "63zJbXUZ_ktB"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(16, 10), sharex=True)\n",
        "\n",
        "plot_order = [(0, 0), (1, 0), (2, 0), (0, 1), (1, 1), (2, 1)]\n",
        "\n",
        "for i in range(5):\n",
        "    r, c = plot_order[i]\n",
        "    ax = axes[r, c]\n",
        "\n",
        "    df_plot = results[i]['price_history'].set_index('Date')[['buy&hold', 'strategy']]\n",
        "    df_plot.plot(ax=ax)\n",
        "\n",
        "    ax.set_title(f'Testing Window {i+1}')\n",
        "    ax.set_ylabel('Portfolio Value')\n",
        "    ax.grid(True)\n",
        "\n",
        "r, c = plot_order[5]  # (2, 1)\n",
        "axes[r, c].axis('off')\n",
        "\n",
        "plt.xlabel('Date')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}